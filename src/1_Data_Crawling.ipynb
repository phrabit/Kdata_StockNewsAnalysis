{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbbd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings # 경고창 무시\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a9e2f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Crolling:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conn = pymysql.connect(user= 'root',passwd  = '1234',host= \"\",port=3306,db='stock',charset = 'utf8')\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        self.driver.implicitly_wait(3)\n",
    "        self.driver.maximize_window()\n",
    "        \n",
    "        \n",
    "    def Stock_ID(self):\n",
    "        for i in range(1, 21):\n",
    "            url = f'https://finance.naver.com/sise/entryJongmok.naver?&page={i}'\n",
    "            self.driver.get(url)\n",
    "            self.driver.implicitly_wait(5)\n",
    "            html = self.driver.page_source \n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            for j in range(3, 13):\n",
    "                id = [i['href'].split(\"=\")[1] for i in soup.select(f'body > div > table.type_1 > tbody > tr:nth-child({j}) > td.ctg > a')]\n",
    "                name = [i.text for i in soup.select(f'body > div > table.type_1 > tbody > tr:nth-child({j}) > td.ctg > a')]\n",
    "                sql = (id, name)\n",
    "                self.cur.execute('INSERT IGNORE INTO Stock_ID (id, name) VALUES (%s ,%s)', sql)\n",
    "                self.conn.commit()\n",
    "            print(f'{i}/20 페이지 완료')\n",
    "        self.driver.quit()\n",
    "        \n",
    "        \n",
    "    def Stock_Price(self):\n",
    "        self.cur.execute('SELECT id FROM Stock_ID;')\n",
    "        stock_id = self.cur.fetchall()\n",
    "        for id in stock_id:\n",
    "            for i in range(1, 10):\n",
    "                url = f'https://finance.naver.com/item/sise_day.naver?code={id[0]}&page={i}'\n",
    "                self.driver.get(url)\n",
    "                self.driver.implicitly_wait(5)\n",
    "                html = self.driver.page_source \n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                for j in [3,4,5,6,7,11,12,13,14,15]:\n",
    "                    date = soup.select_one(f'body > table.type2 > tbody > tr:nth-child({j}) > td:nth-child(1) > span').text\n",
    "                    closing_price = soup.select_one(f'body > table.type2 > tbody > tr:nth-child({j}) > td:nth-child(2) > span').text.replace(',','')\n",
    "                    market_price = soup.select_one(f'body > table.type2 > tbody > tr:nth-child({j}) > td:nth-child(4) > span').text.replace(',','')\n",
    "                    high_price = soup.select_one(f'body > table.type2 > tbody > tr:nth-child({j}) > td:nth-child(5) > span').text.replace(',','')\n",
    "                    low_price = soup.select_one(f'body > table.type2 > tbody > tr:nth-child({j}) > td:nth-child(6) > span').text.replace(',','')\n",
    "                    sql = (id[0], date, closing_price, market_price, high_price, low_price)\n",
    "                    self.cur.execute('INSERT IGNORE INTO Stock_Price3 (stock_id , date, closing_price, market_price, high_price, low_price) VALUES (%s ,%s ,%s ,%s ,%s ,%s)', sql)\n",
    "                    self.conn.commit()\n",
    "                    #break\n",
    "                else:\n",
    "                    continue\n",
    "                if date == '2023.04.27':\n",
    "                    break\n",
    "        self.conn.close()\n",
    "        self.driver.quit()\n",
    "        \n",
    "        \n",
    "    def News(self):\n",
    "        self.cur.execute('SELECT id FROM Stock_ID;')\n",
    "        stock_id = self.cur.fetchall()\n",
    "        for idx,id in enumerate(stock_id):\n",
    "            for i in range(1, 500):\n",
    "                url = f'https://finance.naver.com/item/news_news.naver?code={id[0]}&page={i}&sm=entity_id.basic&clusterId='\n",
    "                self.driver.get(url)\n",
    "                self.driver.implicitly_wait(5)\n",
    "                html = self.driver.page_source \n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                #date = [i.text for i in self.driver.find_elements_by_class_name(\"date\")]\n",
    "                date = [i.text for i in self.driver.find_elements(By.CLASS_NAME,\"date\")]\n",
    "                for j in soup.select('body > div > table.type5 > tbody'):\n",
    "                    data = j.find_all(\"a\")\n",
    "                    data = [i[\"href\"] for i in data if i[\"href\"] != \"#\"]\n",
    "                    for da,de in zip(data,date):\n",
    "                        if de == '':\n",
    "                            continue\n",
    "                        if de < '2023.05.01':\n",
    "                            break\n",
    "                        try:\n",
    "                            url = \"https://finance.naver.com\" + da\n",
    "                            self.driver.get(url)\n",
    "                            news_text_elements = self.driver.find_elements(By.ID, 'news_read')\n",
    "                            if len(news_text_elements) > 0:\n",
    "                                news_text = news_text_elements[0].text\n",
    "                                self.cur.execute('INSERT IGNORE INTO Stock_News (stock_id, text, date) VALUES (%s ,%s, %s)', (id[0], news_text, de))\n",
    "                                self.conn.commit()\n",
    "                                #print(f\"Inserted stock_id={id[0]}, date={de}\")\n",
    "                            else:\n",
    "                                print(\"해당 요소를 찾지 못했습니다.\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"에러가 발생했습니다 : {e}\")\n",
    "                            continue\n",
    "                if de == '':\n",
    "                    continue\n",
    "                if de < '2023.05.01':\n",
    "                    break\n",
    "            print(f'{idx+1}/{len(stock_id)}')\n",
    "        self.conn.close()\n",
    "        self.driver.quit()\n",
    "    \n",
    "\n",
    "Crolling().Stock_Price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4debda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB에 저장된 레코드, CSV파일로 export하기\n",
    "\n",
    "import csv\n",
    "import pymysql\n",
    "\n",
    "def export_to_csv():\n",
    "    db_host = 'localhost'\n",
    "    db_user = 'root'\n",
    "    db_password = '1234'\n",
    "    db_name = 'stock'\n",
    "\n",
    "    # DB 연결\n",
    "    conn = pymysql.connect(host=db_host, user=db_user, password=db_password, db=db_name)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # 쿼리 실행\n",
    "    cur.execute('SELECT * FROM Stock_Price3;')\n",
    "    data = cur.fetchall()\n",
    "\n",
    "    # CSV 파일로 내보내기\n",
    "    with open('stock_price.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['stock_id', 'date', 'closing_price', 'market_price', 'high_price', 'low_price'])\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "export_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998db769",
   "metadata": {},
   "source": [
    "## 중복 제거된 뉴스 기사 csv로 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e762e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pymysql\n",
    "\n",
    "def export_to_csv():\n",
    "    db_host = 'localhost'\n",
    "    db_user = 'root'\n",
    "    db_password = '1234'\n",
    "    db_name = 'stock'\n",
    "\n",
    "    # DB 연결\n",
    "    conn = pymysql.connect(host=db_host, user=db_user, password=db_password, db=db_name)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # 쿼리 실행\n",
    "    cur.execute('SELECT DISTINCT stock_id, text, date FROM stock_news;')\n",
    "    data = cur.fetchall()\n",
    "\n",
    "    # CSV 파일로 내보내기\n",
    "    with open('stock_distinct_news.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['stock_id', 'text', 'date'])\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "export_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d071d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
